<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><title>‘All possible sounds’: speech, music, and the emergence of machine listening &#183; Sean Dockray</title>
<meta name=title content="‘All possible sounds’: speech, music, and the emergence of machine listening &#183; Sean Dockray"><script type=text/javascript src=/js/appearance.min.022d0ebc3b46a335eb1c7ef79b7f2de143d7cd5156d433638592ef1ce5f8554e.js integrity="sha256-Ai0OvDtGozXrHH73m38t4UPXzVFW1DNjhZLvHOX4VU4="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.324fc56d8e6cf2c6434c24fc91ce12df9272c21023933fe3fa434ec56f887445.css integrity="sha256-Mk/FbY5s8sZDTCT8kc4S35JywhAjkz/j+kNOxW+IdEU="><meta name=description content="
      
        Attribution: James E. K. Parker with Sean Dockray.
Published: Sound Studies, Volume 9, 2023 - Issue 2: Forensic voices: cultures of sonic detection and identification in the West (Editors: Karin Bijsterveld and Anna Kvicalova)
“Machine listening” is one common term for a fast-growing interdisciplinary field of science and engineering that “uses signal processing and machine learning to extract useful information from sound”. This article contributes to the critical literature on machine listening by presenting some of its history as a field.
      
    "><link rel=canonical href=https://somethingilearned.today/writing/all-possible-sounds/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:title" content="‘All possible sounds’: speech, music, and the emergence of machine listening"><meta property="og:description" content="Attribution: James E. K. Parker with Sean Dockray.
Published: Sound Studies, Volume 9, 2023 - Issue 2: Forensic voices: cultures of sonic detection and identification in the West (Editors: Karin Bijsterveld and Anna Kvicalova)
“Machine listening” is one common term for a fast-growing interdisciplinary field of science and engineering that “uses signal processing and machine learning to extract useful information from sound”. This article contributes to the critical literature on machine listening by presenting some of its history as a field."><meta property="og:type" content="article"><meta property="og:url" content="https://somethingilearned.today/writing/all-possible-sounds/"><meta property="article:section" content="writing"><meta name=twitter:card content="summary"><meta name=twitter:title content="‘All possible sounds’: speech, music, and the emergence of machine listening"><meta name=twitter:description content="Attribution: James E. K. Parker with Sean Dockray.
Published: Sound Studies, Volume 9, 2023 - Issue 2: Forensic voices: cultures of sonic detection and identification in the West (Editors: Karin Bijsterveld and Anna Kvicalova)
“Machine listening” is one common term for a fast-growing interdisciplinary field of science and engineering that “uses signal processing and machine learning to extract useful information from sound”. This article contributes to the critical literature on machine listening by presenting some of its history as a field."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"‘All possible sounds’: speech, music, and the emergence of machine listening","headline":"‘All possible sounds’: speech, music, and the emergence of machine listening","abstract":"Attribution: James E. K. Parker with Sean Dockray.\nPublished: Sound Studies, Volume 9, 2023 - Issue 2: Forensic voices: cultures of sonic detection and identification in the West (Editors: Karin Bijsterveld and Anna Kvicalova)\n“Machine listening” is one common term for a fast-growing interdisciplinary field of science and engineering that “uses signal processing and machine learning to extract useful information from sound”. This article contributes to the critical literature on machine listening by presenting some of its history as a field.","inLanguage":"en","url":"https:\/\/somethingilearned.today\/writing\/all-possible-sounds\/","author":{"@type":"Person","name":"Sean Dockray"},"mainEntityOfPage":"true","wordCount":"238"}</script><meta name=author content="Sean Dockray"><link href=https://twitter.com/seandockray rel=me><script async src="https://www.googletagmanager.com/gtag/js?id=G-Z00B9CFSF6"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Z00B9CFSF6",{anonymize_ip:!1})}</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold pe-2 text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral print:hidden sm:py-10"><nav class="flex items-start justify-between sm:items-center"><div class="z-40 flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Sean Dockray</a></div><label id=menu-button for=menu-controller class="block sm:hidden"><input type=checkbox id=menu-controller class=hidden><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="fixed inset-0 z-30 invisible w-full h-full m-auto overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex flex-col w-full px-6 py-6 mx-auto overflow-visible list-none max-w-7xl text-end sm:px-14 sm:py-10 sm:pt-10 md:px-24 lg:px-32"><li class=mb-1><span class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class="mb-1 group"><a href=/projects/overview/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">projects</span></a></li><li class="mb-1 group"><a href=/writing/overview/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">writing</span></a></li><li class="mb-1 group"><a href=/about/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">about</span></a></li><li class="mb-1 group"><a href=/contact/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">contact</span></a></li><li class="mb-1 group"><a href=/contact/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></a></li></ul></div></label><ul class="flex-row hidden list-none text-end sm:flex"><li class="mb-1 group sm:mb-0 sm:me-7 sm:last:me-0"><a href=/projects/overview/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">projects</span></a></li><li class="mb-1 group sm:mb-0 sm:me-7 sm:last:me-0"><a href=/writing/overview/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">writing</span></a></li><li class="mb-1 group sm:mb-0 sm:me-7 sm:last:me-0"><a href=/about/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">about</span></a></li><li class="mb-1 group sm:mb-0 sm:me-7 sm:last:me-0"><a href=/contact/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">contact</span></a></li><li class="mb-1 group sm:mb-0 sm:me-7 sm:last:me-0"><a href=/contact/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></a></li></ul></nav></header><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">‘All possible sounds’: speech, music, and the emergence of machine listening</h1><div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-prose grow"><p><strong>Attribution:</strong> James E. K. Parker with Sean Dockray.<br><strong>Published:</strong> <em>Sound Studies</em>, Volume 9, 2023 - Issue 2: <a href=https://www.tandfonline.com/toc/rfso20/9/2 target=_blank rel=noreferrer>Forensic voices: cultures of sonic detection and identification in the West</a> (Editors: Karin Bijsterveld and Anna Kvicalova)</p><blockquote><p>“Machine listening” is one common term for a fast-growing interdisciplinary field of science and engineering that “uses signal processing and machine learning to extract useful information from sound”. This article contributes to the critical literature on machine listening by presenting some of its history as a field. From the 1940s to the 1990s, work on artificial intelligence and audio developed along two streams. There was work on speech recognition/understanding, and work in computer music. In the early 1990s, another stream began to emerge. At institutions such as MIT Media Lab and Stanford’s CCRMA, researchers started turning towards “more fundamental problems of audition”. Propelled by work being done by and alongside musicians, speech and music would increasingly be understood by computer scientists as particular sounds within a broader “auditory scene”. Researchers began to develop machine listening systems for a more diverse range of sounds and classification tasks: often in the service of speech recognition, but also increasingly for their own sake. The soundscape itself was becoming an object of computational concern. Today, the ambition is “to cover all possible sounds”. That is the aspiration with which we must now contend politically, and which this article sets out to historicise and understand.</p></blockquote><p><a href=https://www.tandfonline.com/doi/full/10.1080/20551940.2023.2195057 target=_blank rel=noreferrer>Full text available here</a></p></div></section><footer class="pt-8 max-w-prose print:hidden"></footer></article><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div><p class="text-xs text-neutral-500 dark:text-neutral-400">and <a href=https://obsidian.md>Obsidian</a></p></footer></div></body></html>